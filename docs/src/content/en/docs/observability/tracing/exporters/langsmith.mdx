---
title: "LangSmith Exporter | Tracing | Observability"
description: "Send traces to LangSmith for LLM observability and evaluation"
packages:
  - "@mastra/core"
  - "@mastra/langsmith"
  - "@mastra/observability"
---

# LangSmith Exporter

[LangSmith](https://smith.langchain.com/) is LangChain's platform for monitoring and evaluating LLM applications. The LangSmith exporter sends your traces to LangSmith, providing insights into model performance, debugging capabilities, and evaluation workflows.

## Installation

```bash npm2yarn
npm install @mastra/langsmith@latest
```

## Configuration

### Prerequisites

1. **LangSmith Account**: Sign up at [smith.langchain.com](https://smith.langchain.com)
1. **API Key**: Generate an API key in LangSmith Settings â†’ API Keys
1. **Environment Variables**: Set your credentials

```bash title=".env"
# Required
LANGSMITH_API_KEY=ls-xxxxxxxxxxxx

# Optional
LANGCHAIN_PROJECT=my-project  # Default project for traces
LANGSMITH_BASE_URL=https://api.smith.langchain.com  # For self-hosted
```

### Zero-Config Setup

With environment variables set, use the exporter with no configuration:

```typescript title="src/mastra/index.ts"
import { Mastra } from '@mastra/core'
import { Observability } from '@mastra/observability'
import { LangSmithExporter } from '@mastra/langsmith'

export const mastra = new Mastra({
  observability: new Observability({
    configs: {
      langsmith: {
        serviceName: 'my-service',
        exporters: [new LangSmithExporter()],
      },
    },
  }),
})
```

### Explicit Configuration

You can also pass credentials directly (takes precedence over environment variables):

```typescript title="src/mastra/index.ts"
import { Mastra } from '@mastra/core'
import { Observability } from '@mastra/observability'
import { LangSmithExporter } from '@mastra/langsmith'

export const mastra = new Mastra({
  observability: new Observability({
    configs: {
      langsmith: {
        serviceName: 'my-service',
        exporters: [
          new LangSmithExporter({
            apiKey: process.env.LANGSMITH_API_KEY,
          }),
        ],
      },
    },
  }),
})
```

## Configuration Options

### Complete Configuration

```typescript
new LangSmithExporter({
  // Required credentials
  apiKey: process.env.LANGSMITH_API_KEY!,

  // Optional settings
  apiUrl: process.env.LANGSMITH_BASE_URL, // Default: https://api.smith.langchain.com
  projectName: 'my-project', // Project to send traces to (overrides LANGCHAIN_PROJECT env var)
  callerOptions: {
    // HTTP client options
    timeout: 30000, // Request timeout in ms
    maxRetries: 3, // Retry attempts
  },
  logLevel: 'info', // Diagnostic logging: debug | info | warn | error

  // LangSmith-specific options
  hideInputs: false, // Hide input data in UI
  hideOutputs: false, // Hide output data in UI
})
```

### Environment Variables

| Variable | Description |
| - | - |
| `LANGSMITH_API_KEY` | Your LangSmith API key (required) |
| `LANGCHAIN_PROJECT` | Default project name for traces (optional, defaults to "default") |
| `LANGSMITH_BASE_URL` | API URL for self-hosted instances (optional) |

The `projectName` config option takes precedence over the `LANGCHAIN_PROJECT` environment variable, allowing you to programmatically route traces to different projects.

## Dynamic Configuration

You can dynamically override LangSmith settings per-span using `withLangsmithMetadata`. This is useful for routing traces to different projects based on runtime conditions (e.g., customer, environment, or feature).

### Using the Helper

Use `withLangsmithMetadata` with `buildTracingOptions` to set LangSmith-specific options:

```typescript title="src/agents/support-agent.ts"
import { Agent } from '@mastra/core/agent'
import { buildTracingOptions } from '@mastra/observability'
import { withLangsmithMetadata } from '@mastra/langsmith'

export const supportAgent = new Agent({
  id: 'support-agent',
  name: 'support-agent',
  instructions: 'You are a helpful support agent.',
  model: 'openai/gpt-4o',
  defaultOptions: {
    tracingOptions: buildTracingOptions(withLangsmithMetadata({ projectName: 'customer-support' })),
  },
})
```

### Dynamic Project Routing

Use `requestContext` to route traces to different projects based on runtime conditions.

```typescript title="src/mastra/agents/support-agent.ts"
import { Agent } from '@mastra/core/agent'
import { buildTracingOptions } from '@mastra/observability'
import { withLangsmithMetadata } from '@mastra/langsmith'

export const supportAgent = new Agent({
  id: 'support-agent',
  name: 'support-agent',
  instructions: 'You are a helpful support agent.',
  model: 'openai/gpt-4o',
  defaultOptions: ({ requestContext }) => {
    const userTier = requestContext?.get('user-tier') as string
    const userId = requestContext?.get('user-id') as string

    return {
      tracingOptions: buildTracingOptions(
        withLangsmithMetadata({
          projectName: userTier === 'enterprise' ? 'enterprise-traces' : 'standard-traces',
          sessionId: userId,
        }),
      ),
    }
  },
})
```

### Available Fields

The `withLangsmithMetadata` helper accepts these fields:

| Field | Type | Description |
| - | - | - |
| `projectName` | string | Override the project for this trace |
| `sessionId` | string | Group related traces by session |
| `sessionName` | string | Display name for the session |

All fields are optional. The helper merges with any existing metadata, so you can call it multiple times or combine with other tracing options.

## Related

- [Tracing Overview](/docs/observability/tracing/overview)
- [LangSmith Documentation](https://docs.smith.langchain.com/)
